{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SNA Project Round - 1 \n",
    "\n",
    "Team: TekloTekloTingTiiiing\n",
    "\n",
    "Members: \n",
    "\n",
    "1) 21ucs204 - Sindhi Krish Kamal\n",
    "2) 21ucs158 - Prashant Singh Shekhawat\n",
    "3) 21ucs237 - Yashodhan Sonune\n",
    "4) 21ucs183 - Sarvagya Acharya\n",
    "\n",
    "Datasets chosen:\n",
    "- US Power Grid ( http://konect.cc/networks/opsahl-powergrid/ )\n",
    "- Yeast network ( http://konect.cc/networks/moreno_propro/ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the important libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the undirected datasets\n",
    "def load_Undirected_Graph(file_path):\n",
    "    \"\"\"\n",
    "    Load dataset from file path\n",
    "    \"\"\"\n",
    "    # Depending on the format of your dataset, you might need to adjust the loading method\n",
    "    # For example, if it's an edgelist, you can use nx.read_edgelist()\n",
    "    G = nx.read_edgelist(file_path)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize network statistics\n",
    "def summarize_network_stats(G):\n",
    "    \"\"\"\n",
    "    Summarize network statistics\n",
    "    \"\"\"\n",
    "    # Degree distribution\n",
    "    degrees = dict(G.degree())\n",
    "    degree_values = list(degrees.values())\n",
    "    max_degree = max(degree_values)\n",
    "    min_degree = min(degree_values)\n",
    "    avg_degree = sum(degree_values) / len(G)\n",
    "    std_degree = pd.Series(degree_values).std()\n",
    "\n",
    "    #Plot degree distribution\n",
    "    plt.bar(degrees.keys(), degrees.values() ,color='skyblue')\n",
    "    plt.ylim(0, 150)\n",
    "    plt.title(\"Degree Distribution\")\n",
    "    plt.xlabel(\"Node_ID\")\n",
    "    plt.ylabel(\"Degree\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot kernel density estimation (KDE) plot of node degree\n",
    "    sns.kdeplot(degree_values, color='skyblue', fill=True)\n",
    "    plt.xlim(0, 150)\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Node Degree Distribution (KDE plot)')\n",
    "    plt.show()\n",
    "\n",
    "    # Output statistics\n",
    "    print(\"Max Degree:\", max_degree)\n",
    "    print(\"Min Degree:\", min_degree)\n",
    "    print(\"Average Degree:\", avg_degree)\n",
    "    print(\"Standard Deviation of Degree Distribution:\", std_degree)\n",
    "    print(\"Total number of Nodes in the graph:\", G.number_of_nodes())\n",
    "    print(\"Total number of Edges in the graph:\", G.number_of_edges())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate centrality measures\n",
    "def calculate_centrality_measures(G):\n",
    "    \"\"\"\n",
    "    Calculate centrality measures\n",
    "    \"\"\"\n",
    "    # Degree centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    print(\"Degree Centrality:\")\n",
    "    print(degree_centrality)\n",
    "    rounded_degree_centrality = np.round(list(degree_centrality.values()), 5)\n",
    "    print(rounded_degree_centrality)\n",
    "    # Plot histogram of degree centrality\n",
    "    plt.hist(rounded_degree_centrality, bins=1000, color='skyblue')\n",
    "    plt.xlim(0, 0.01)\n",
    "    plt.ylim(0, 300)\n",
    "    plt.title(\"Degree Centrality Distribution\")\n",
    "    plt.xlabel(\"Degree Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus degree centrality\n",
    "    plt.scatter(list(degree_centrality.keys()), list(degree_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.01)\n",
    "    plt.title(\"Node ID vs Degree Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Degree Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Eigenvector centrality\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    print(\"\\nEigenvector Centrality:\")\n",
    "    print(eigenvector_centrality)\n",
    "\n",
    "    # Plot histogram of eigenvector centrality\n",
    "    plt.hist(eigenvector_centrality.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.04)\n",
    "    plt.title(\"Eigenvector Centrality Distribution\")\n",
    "    plt.xlabel(\"Eigenvector Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus eigenvector centrality\n",
    "    plt.scatter(list(eigenvector_centrality.keys()), list(eigenvector_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.2)\n",
    "    plt.title(\"Node ID vs Eigenvector Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Eigenvector Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Katz centrality\n",
    "    katz_centrality = nx.katz_centrality_numpy(G, alpha=0.1)\n",
    "    print(\"\\nKatz Centrality:\")\n",
    "    print(katz_centrality)\n",
    "\n",
    "    # Plot histogram of Katz centrality\n",
    "    plt.hist(katz_centrality.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.06)\n",
    "    plt.title(\"Katz Centrality Distribution\")\n",
    "    plt.xlabel(\"Katz Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus Katz centrality\n",
    "    plt.scatter(list(katz_centrality.keys()), list(katz_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.title(\"Node ID vs Katz Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Katz Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # PageRank centrality\n",
    "    pagerank_centrality = nx.pagerank(G)\n",
    "    print(\"\\nPageRank Centrality:\")\n",
    "    print(pagerank_centrality)\n",
    "\n",
    "    # Plot histogram of PageRank centrality\n",
    "    plt.hist(pagerank_centrality.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.0004)\n",
    "    plt.title(\"PageRank Centrality Distribution\")\n",
    "    plt.xlabel(\"PageRank Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus PageRank centrality\n",
    "    plt.scatter(list(pagerank_centrality.keys()), list(pagerank_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.0004)\n",
    "    plt.title(\"Node ID vs PageRank Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"PageRank Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Clustering coefficients\n",
    "    local_clustering = nx.clustering(G)\n",
    "    global_clustering = nx.average_clustering(G)\n",
    "    print(\"\\nLocal Clustering Coefficients:\")\n",
    "    print(local_clustering)\n",
    "    print(\"\\nGlobal Clustering Coefficient:\")\n",
    "    print(global_clustering)\n",
    "\n",
    "    # Plot histogram of local clustering coefficients\n",
    "    plt.hist(local_clustering.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.1)\n",
    "    plt.ylim(0, 20)\n",
    "    plt.title(\"Local Clustering Coefficients Distribution\")\n",
    "    plt.xlabel(\"Local Clustering Coefficients\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot node ID versus local clustering centrality\n",
    "    plt.scatter(list(local_clustering.keys()), list(local_clustering.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.1)\n",
    "    plt.title(\"Node ID vs Local Clustering Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Local Clustering Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, k = 1000)\n",
    "    print(\"\\nBetweenness Centrality:\")\n",
    "    print(betweenness_centrality)\n",
    "\n",
    "    # Plot histogram of betweenness centrality\n",
    "    plt.hist(betweenness_centrality.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.003)\n",
    "    plt.title(\"Betweenness Centrality Distribution\")\n",
    "    plt.xlabel(\"Betweenness Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus betweenness centrality\n",
    "    plt.scatter(list(betweenness_centrality.keys()), list(betweenness_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.003)\n",
    "    plt.title(\"Node ID vs Betweenness Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Betweenness Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Closeness centrality\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    print(\"\\nCloseness Centrality:\")\n",
    "    print(closeness_centrality)\n",
    "\n",
    "    # Plot histogram of closeness centrality\n",
    "    plt.hist(closeness_centrality.values(), bins=10000, color='skyblue')\n",
    "    plt.xlim(0, 0.5)\n",
    "    plt.title(\"Closeness Centrality Distribution\")\n",
    "    plt.xlabel(\"Closeness Centrality\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot node ID versus closeness centrality\n",
    "    plt.scatter(list(closeness_centrality.keys()), list(closeness_centrality.values()), color='black', alpha=0.5)\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.title(\"Node ID vs Closeness Centrality\")\n",
    "    plt.xlabel(\"Node ID\")\n",
    "    plt.ylabel(\"Closeness Centrality\")\n",
    "    plt.show()\n",
    "\n",
    "    # Reciprocity\n",
    "    reciprocity = nx.reciprocity(G)\n",
    "    print(\"\\nReciprocity:\")\n",
    "    print(reciprocity)\n",
    "\n",
    "    # Transitivity\n",
    "    transitivity = nx.transitivity(G)\n",
    "    print(\"\\nTransitivity:\")\n",
    "    print(transitivity)\n",
    "\n",
    "    return pd.DataFrame({\"Degree Centrality\": degree_centrality, \"Eigenvector Centrality\": eigenvector_centrality, \"Katz Centrality\": katz_centrality, \"PageRank Centrality\": pagerank_centrality, \"Betweenness Centrality\": betweenness_centrality, \"Closeness Centrality\": closeness_centrality})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_values(centrality_measures):\n",
    "    # Function to get top N values and corresponding node IDs for each centrality measure\n",
    "    def get_top_n_centrality_values(centrality_measures, top_n=10):\n",
    "        top_n_values = {}\n",
    "        for measure, values in centrality_measures.items():\n",
    "            sorted_values = sorted(values.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "            top_n_values[measure] = sorted_values\n",
    "        return top_n_values\n",
    "\n",
    "    # Get top 10 values for each centrality measure\n",
    "    top_10_centrality_values = get_top_n_centrality_values(centrality_measures)\n",
    "\n",
    "    # Print the top 10 values for each centrality measure\n",
    "    for measure, values in top_10_centrality_values.items():\n",
    "        print(f\"Top 10 values for {measure}:\")\n",
    "        for node, centrality_value in values:\n",
    "            print(f\"Node: {node}, Centrality Value: {centrality_value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_BA_network():\n",
    "#     # Initialize a BA network with 5 initial nodes\n",
    "#     BA_network = nx.barabasi_albert_graph(10000, 5)\n",
    "#     return BA_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_BA_network():\n",
    "    def initialize_ba_network(m0, m, n):\n",
    "        \"\"\"\n",
    "        Initialize a Barabási-Albert (BA) scale-free network.\n",
    "        \n",
    "        Parameters:\n",
    "            - m0: Initial number of nodes in the network.\n",
    "            - m: Number of edges to attach from a new node to existing nodes.\n",
    "            - n: Total number of nodes desired in the network.\n",
    "        \n",
    "        Returns:\n",
    "            - G: Barabási-Albert network with 'n' nodes.\n",
    "        \"\"\"\n",
    "        # Initialize a complete graph with m0 nodes\n",
    "        G = nx.complete_graph(m0)\n",
    "        \n",
    "        # Add nodes with preferential attachment\n",
    "        for new_node in range(m0, n):\n",
    "            # Select m nodes to attach to the new node\n",
    "            targets = list(range(new_node))\n",
    "            selected_nodes = []\n",
    "            for _ in range(m):\n",
    "                if targets:\n",
    "                    node = random.choice(targets)\n",
    "                    targets.remove(node)\n",
    "                    selected_nodes.append(node)\n",
    "            \n",
    "            # Add edges between the new node and selected nodes\n",
    "            for selected_node in selected_nodes:\n",
    "                G.add_edge(new_node, selected_node)\n",
    "        \n",
    "        return G\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    m0 = 5  # Initial number of nodes\n",
    "    m = 10   # Number of edges to attach from a new node to existing nodes\n",
    "    n = 10000  # Total number of nodes desired in the network\n",
    "\n",
    "    # Generate BA network\n",
    "    ba_network = initialize_ba_network(m0, m, n)\n",
    "    return ba_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_BA_network(G):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=False, node_size=5)\n",
    "    plt.title(\"BA Network Visualization\")\n",
    "    plt.savefig('Barabasi-Albert.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def independent_cascade_model(G, num_iterations=10):\n",
    "    average_steps = 0\n",
    "    for i in range(num_iterations):\n",
    "        # Randomly select a starting node\n",
    "        source_node = random.choice(list(G.nodes()))\n",
    "        \n",
    "        # Initialize activated nodes with the source node\n",
    "        activated_nodes = {source_node}\n",
    "        newly_activated_nodes = {source_node}\n",
    "        steps = 0\n",
    "        \n",
    "        # Continue until no new nodes are activated\n",
    "        while newly_activated_nodes:\n",
    "            steps += 1\n",
    "            newly_activated_nodes = set()\n",
    "            for node in activated_nodes:\n",
    "                # Get neighbors of the node\n",
    "                neighbors = list(G.neighbors(node))\n",
    "                # Activate neighbors based on random activation probabilities\n",
    "                for neighbor in neighbors:\n",
    "                    if neighbor not in activated_nodes:\n",
    "                        activation_probability = random.random()\n",
    "                        if activation_probability <= G[node][neighbor]['activation_probability']:\n",
    "                            newly_activated_nodes.add(neighbor)\n",
    "            activated_nodes |= newly_activated_nodes  # Union operation to add newly activated nodes\n",
    "        average_steps += steps\n",
    "    return average_steps / num_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_giant_component_size(G):\n",
    "    giant_component_size = len(max(nx.connected_components(G), key=len))\n",
    "    return giant_component_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate giant component for all networks\n",
    "def calculate_giant_component(G):\n",
    "    giant_component = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(giant_component)\n",
    "\n",
    "# Visualize the giant component\n",
    "def visualize_giant_component(G, name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=False, node_size=5)\n",
    "    plt.title(name + \" Giant Component Visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Information Diffusion in the Networks\n",
    "def initialize_activation_probabilities(G):\n",
    "    for node in G.nodes():\n",
    "        # Get the outgoing edges of the node\n",
    "        outgoing_edges = list(G.edges(node))\n",
    "        # Store the initial random values for activation probabilities\n",
    "        initial_activation_probabilities = [random.random() for _ in outgoing_edges]\n",
    "        # Calculate the sum of activation probabilities for outgoing edges\n",
    "        sum_activation_probabilities = sum(initial_activation_probabilities)\n",
    "        # Assign activation probabilities for outgoing edges such that their sum is equal to 1\n",
    "        for edge, p in zip(outgoing_edges, initial_activation_probabilities):\n",
    "            G.edges[edge]['activation_probability'] = p / sum_activation_probabilities\n",
    "\n",
    "# Visualize activation probabilities as a heatmap\n",
    "def visualize_activation_probabilities(G):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    edge_labels = {(u, v): G.edges[u, v]['activation_probability'] for u, v in G.edges()}\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=False, node_size=5)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "    plt.title(\"Activation Probabilities Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Load datasets\n",
    "    dataset1_path = \"./download.tsv.opsahl-powergrid/opsahl-powergrid/out.opsahl-powergrid\"\n",
    "    dataset2_path = \"./download.tsv.moreno_propro/moreno_propro/out.moreno_propro_propro\"\n",
    "    G1 = load_Undirected_Graph(dataset1_path)\n",
    "    G2 = load_Undirected_Graph(dataset2_path)\n",
    "    G3_BA = generate_BA_network()\n",
    "    #visualize_BA_network(G3_BA)\n",
    "\n",
    "    # nx.draw_networkx_edges(G1, pos=nx.spring_layout(G1))\n",
    "    # plt.savefig('powergrid.png')\n",
    "    \n",
    "    # nx.draw_networkx_edges(G2, pos=nx.spring_layout(G2))\n",
    "    # plt.savefig('yeast.png')\n",
    "\n",
    "    # Summarize network statistics\n",
    "    # print(\"Dataset 1 Statistics:\")\n",
    "    # summarize_network_stats(G1)\n",
    "    # print(\"\\nDataset 2 Statistics:\")\n",
    "    # summarize_network_stats(G2)\n",
    "    print(\"\\nGraph-3(BA_model) Statistics:\")\n",
    "    summarize_network_stats(G3_BA)\n",
    "\n",
    "    # #Giant Components\n",
    "    G1_Giant_component_size = calculate_giant_component_size(G1)\n",
    "    G2_Giant_component_size = calculate_giant_component_size(G2)\n",
    "    G3_BA_Giant_component_size = calculate_giant_component_size(G3_BA)\n",
    "\n",
    "    G1_Giant_component = calculate_giant_component(G1)\n",
    "    G2_Giant_component = calculate_giant_component(G2)\n",
    "    G3_BA_Giant_component = calculate_giant_component(G3_BA)\n",
    "\n",
    "    print(f\"Dataset-1 Giant component size: {G1_Giant_component_size}\")\n",
    "    print(f\"Dataset-1 Giant component number of nodes: {G1_Giant_component.number_of_nodes()}\")\n",
    "    print(f\"Dataset-1 Giant component number of edges: {G1_Giant_component.number_of_edges()}\")\n",
    "    visualize_giant_component(G1_Giant_component, \"Dataset1\")\n",
    "\n",
    "    print(f\"Dataset-2 Giant component size: {G2_Giant_component_size}\")\n",
    "    print(f\"Dataset-2 Giant component number of nodes: {G2_Giant_component.number_of_nodes()}\")\n",
    "    print(f\"Dataset-2 Giant component number of edges: {G2_Giant_component.number_of_edges()}\")\n",
    "    visualize_giant_component(G2_Giant_component, \"Dataset2\")\n",
    "\n",
    "    print(f\"BA-Model Giant component size: {G3_BA_Giant_component_size}\")\n",
    "    print(f\"BA-Model Giant component number of nodes: {G3_BA_Giant_component.number_of_nodes()}\")\n",
    "    print(f\"BA-Model Giant component number of edges: {G3_BA_Giant_component.number_of_edges()}\")\n",
    "    visualize_giant_component(G3_BA_Giant_component, \"Barabasi-Albert Network\")\n",
    "\n",
    "\n",
    "    # #Information Diffusion\n",
    "    initialize_activation_probabilities(G1)\n",
    "    visualize_activation_probabilities(G1)\n",
    "    G1_ICM = independent_cascade_model(G1)\n",
    "    print(f\"Average nuumber of steps required to diffuse information for dataset 1: {G1_ICM}\")\n",
    "\n",
    "    initialize_activation_probabilities(G2)\n",
    "    visualize_activation_probabilities(G2)\n",
    "    G2_ICM = independent_cascade_model(G2)\n",
    "    print(f\"Average nuumber of steps required to diffuse information for dataset 2: {G2_ICM}\")\n",
    "\n",
    "    initialize_activation_probabilities(G3_BA)\n",
    "    visualize_activation_probabilities(G3_BA)\n",
    "    G3_ICM = independent_cascade_model(G3_BA)\n",
    "    print(f\"Average nuumber of steps required to diffuse information for Network 3(BA_model): {G3_ICM}\")\n",
    "\n",
    "    #Calculate centrality measures\n",
    "    # print(\"Dataset 1 centrality measures:\")\n",
    "    # centrality_measures_1 = calculate_centrality_measures(G1)\n",
    "    # centrality_stats1 = centrality_measures_1.describe()\n",
    "    # # Plot heatmap\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.heatmap(centrality_stats1, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    # plt.title(\"Descriptive Statistics of Centrality Measures for Network-1\")\n",
    "    # plt.show()\n",
    "    # get_top_10_values(centrality_measures_1)\n",
    "\n",
    "    # print(\"\\nDataset 2 centrality measures:\")\n",
    "    # centrality_measures_2 = calculate_centrality_measures(G2)\n",
    "    # centrality_stats2 = centrality_measures_2.describe()\n",
    "    # # Plot heatmap\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # sns.heatmap(centrality_stats2, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    # plt.title(\"Descriptive Statistics of Centrality Measures for Network-2\")\n",
    "    # plt.show()\n",
    "    # get_top_10_values(centrality_measures_2)\n",
    "\n",
    "    \n",
    "    print(\"\\nBA Graph centrality measures:\")\n",
    "    centrality_measures_3 = calculate_centrality_measures(G3_BA)\n",
    "    centrality_stats3 = centrality_measures_3.describe()\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(centrality_stats3, annot=True, fmt=\".2f\", cmap=\"YlGnBu\")\n",
    "    plt.title(\"Descriptive Statistics of Centrality Measures for Network-3(BA model)\")\n",
    "    plt.show()\n",
    "    get_top_10_values(centrality_measures_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
